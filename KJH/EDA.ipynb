{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33afd4b2",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ“ í˜„ì¬ ë…¸íŠ¸ë¶ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ì„¤ì •\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "\n",
    "# ğŸ“„ JSON ë¡œë“œ\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# âœ… ê°œìˆ˜ í™•ì¸\n",
    "print(f\"ğŸ“¦ ì „ì²´ ì„œë¹„ìŠ¤ ê°œìˆ˜: {len(data)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3f04e",
   "metadata": {},
   "source": [
    "## ì¤‘ë³µ í™•ì¸\n",
    "### ì„œë¹„ìŠ¤ëª… ë™ì¼, ID í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4301cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì • ë° JSON ë¡œë“œ\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 1. ì„œë¹„ìŠ¤ëª… â†’ ì„œë¹„ìŠ¤ID ë¦¬ìŠ¤íŠ¸ë¡œ ë§¤í•‘\n",
    "name_to_ids = defaultdict(list)\n",
    "for item in data:\n",
    "    name = item.get(\"ì„œë¹„ìŠ¤ëª…\")\n",
    "    sid = item.get(\"ì„œë¹„ìŠ¤ID\")\n",
    "    name_to_ids[name].append(sid)\n",
    "\n",
    "# 2. ì¤‘ë³µëœ ì„œë¹„ìŠ¤ëª…ë§Œ ì¶”ì¶œ\n",
    "duplicates = {name: sids for name, sids in name_to_ids.items() if len(sids) > 1}\n",
    "\n",
    "# 3. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"â— ì¤‘ë³µëœ ì„œë¹„ìŠ¤ëª… ê°œìˆ˜: {len(duplicates)}ê°œ\\n\")\n",
    "\n",
    "for name, sids in list(duplicates.items())[:10]:  # ì˜ˆì‹œ 10ê°œë§Œ ì¶œë ¥\n",
    "    print(f\"ğŸ” ì„œë¹„ìŠ¤ëª…: {name}\")\n",
    "    print(\"   ì„œë¹„ìŠ¤ID ëª©ë¡:\", sids)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b61c9",
   "metadata": {},
   "source": [
    "### ì„œë¹„ìŠ¤ID ë™ì¼ ì„œë¹„ìŠ¤ëª… í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì • ë° JSON ë¡œë“œ\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 1. ì„œë¹„ìŠ¤ID â†’ ì„œë¹„ìŠ¤ëª… ë¦¬ìŠ¤íŠ¸ë¡œ ë§¤í•‘\n",
    "id_to_names = defaultdict(list)\n",
    "for item in data:\n",
    "    sid = item.get(\"ì„œë¹„ìŠ¤ID\")\n",
    "    name = item.get(\"ì„œë¹„ìŠ¤ëª…\")\n",
    "    id_to_names[sid].append(name)\n",
    "\n",
    "# 2. ì¤‘ë³µëœ ì„œë¹„ìŠ¤IDë§Œ ì¶”ì¶œ\n",
    "duplicates = {sid: names for sid, names in id_to_names.items() if len(names) > 1}\n",
    "\n",
    "# 3. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"â— ì¤‘ë³µëœ ì„œë¹„ìŠ¤ID ê°œìˆ˜: {len(duplicates)}ê°œ\\n\")\n",
    "\n",
    "for sid, names in list(duplicates.items())[:10]:  # ì˜ˆì‹œ 10ê°œë§Œ ì¶œë ¥\n",
    "    print(f\"ğŸ” ì„œë¹„ìŠ¤ID: {sid}\")\n",
    "    print(\"   ì„œë¹„ìŠ¤ëª… ëª©ë¡:\", names)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581911e",
   "metadata": {},
   "source": [
    "### ì„œë¹„ìŠ¤ëª… ë™ì¼í•œ item ëª¨ë‘ ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# JSON ë¡œë“œ\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# íŠ¹ì • ì„œë¹„ìŠ¤ëª…ìœ¼ë¡œ í•„í„°ë§\n",
    "target_name = \"ì„ë©´í”¼í•´ êµ¬ì œê¸‰ì—¬ ì§€ê¸‰\"\n",
    "matching_items = [item for item in data if item.get(\"ì„œë¹„ìŠ¤ëª…\") == target_name]\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ” '{target_name}' ê´€ë ¨ í•­ëª© ìˆ˜: {len(matching_items)}ê°œ\\n\")\n",
    "\n",
    "for i, item in enumerate(matching_items, 1):\n",
    "    print(f\"ğŸ“¦ í•­ëª© {i} (ì„œë¹„ìŠ¤ID: {item.get('ì„œë¹„ìŠ¤ID')})\")\n",
    "    print(json.dumps(item, ensure_ascii=False, indent=2))\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa773853",
   "metadata": {},
   "source": [
    "### ì„œë¹„ìŠ¤ID ë™ì¼í•œ item ëª¨ë‘ ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f502ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# JSON ë¡œë“œ\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# íŠ¹ì • ì„œë¹„ìŠ¤IDë¡œ í•„í„°ë§\n",
    "target_id = \"148000000001\"  # ì—¬ê¸°ì— ì›í•˜ëŠ” ì„œë¹„ìŠ¤ID ì…ë ¥\n",
    "matching_items = [item for item in data if item.get(\"ì„œë¹„ìŠ¤ID\") == target_id]\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ” ì„œë¹„ìŠ¤ID '{target_id}' ê´€ë ¨ í•­ëª© ìˆ˜: {len(matching_items)}ê°œ\\n\")\n",
    "\n",
    "for i, item in enumerate(matching_items, 1):\n",
    "    print(f\"ğŸ“¦ í•­ëª© {i} (ì„œë¹„ìŠ¤ëª…: {item.get('ì„œë¹„ìŠ¤ëª…')})\")\n",
    "    print(json.dumps(item, ensure_ascii=False, indent=2))\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5efa64",
   "metadata": {},
   "source": [
    "### ì„œë¹„ìŠ¤ëª… ë™ì¼í•œ item ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import difflib\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# âœ… ë¹„êµ ëŒ€ìƒ ì„œë¹„ìŠ¤ëª…\n",
    "target_name = \"ì„ë©´í”¼í•´ êµ¬ì œê¸‰ì—¬ ì§€ê¸‰\"\n",
    "\n",
    "# 1. í•´ë‹¹ ì„œë¹„ìŠ¤ëª…ìœ¼ë¡œ í•„í„°ë§\n",
    "matched_items = [item for item in data if item.get(\"ì„œë¹„ìŠ¤ëª…\") == target_name]\n",
    "print(f\"ğŸ” '{target_name}' ê´€ë ¨ í•­ëª© ìˆ˜: {len(matched_items)}ê°œ\")\n",
    "\n",
    "# 2. JSON ë¬¸ìì—´ë¡œ ì •ë ¬í•´ì„œ ë¹„êµ ì¤€ë¹„\n",
    "serialized = [json.dumps(item, sort_keys=True, ensure_ascii=False, indent=2).splitlines() for item in matched_items]\n",
    "\n",
    "# 3. ëª¨ë“  ìŒ ë¹„êµ\n",
    "for (i, j) in combinations(range(len(serialized)), 2):\n",
    "    if serialized[i] != serialized[j]:\n",
    "        print(f\"\\nâ— í•­ëª© {i}ì™€ í•­ëª© {j}ëŠ” ì„œë¡œ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "        diff = difflib.unified_diff(\n",
    "            serialized[i],\n",
    "            serialized[j],\n",
    "            fromfile=f'í•­ëª© {i}',\n",
    "            tofile=f'í•­ëª© {j}',\n",
    "            lineterm=''\n",
    "        )\n",
    "        print(\"\\n\".join(diff))\n",
    "    else:\n",
    "        print(f\"âœ… í•­ëª© {i}ì™€ í•­ëª© {j}ëŠ” ë™ì¼í•©ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90eafb0",
   "metadata": {},
   "source": [
    "### ì„œë¹„ìŠ¤ID ë™ì¼í•œ item ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94380566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ\n",
    "data_path = Path(\"data/combined_service_data.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 1. íŠ¹ì • ì„œë¹„ìŠ¤IDë¡œ í•„í„°ë§\n",
    "target_id = \"148000000001\"\n",
    "matched_items = [item for item in data if item.get(\"ì„œë¹„ìŠ¤ID\") == target_id]\n",
    "\n",
    "print(f\"ğŸ” í•´ë‹¹ ì„œë¹„ìŠ¤ID({target_id})ë¡œ ê²€ìƒ‰ëœ í•­ëª© ìˆ˜: {len(matched_items)}ê°œ\")\n",
    "\n",
    "# 2. ë¹„êµ: ì²« ë²ˆì§¸ í•­ëª© ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ í•­ëª©ë“¤ê³¼ ë¹„êµ\n",
    "base = json.dumps(matched_items[0], sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "for idx, item in enumerate(matched_items[1:], start=1):\n",
    "    current = json.dumps(item, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "    if base != current:\n",
    "        print(f\"\\nâ— í•­ëª© 0ê³¼ í•­ëª© {idx}ëŠ” ì„œë¡œ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "\n",
    "        # ê¸€ì ë‹¨ìœ„ ë¹„êµ\n",
    "        for i, (a, b) in enumerate(zip(base, current)):\n",
    "            if a != b:\n",
    "                print(f\"  ğŸ”¹ ì²« ì°¨ì´ì  at index {i}: '{a}' â‰  '{b}'\")\n",
    "                print(f\"  ğŸ” ê¸°ì¤€ ë¬¸ìì—´ ì¼ë¶€: {base[i-20:i+20]}\")\n",
    "                print(f\"  ğŸ” ë¹„êµ ë¬¸ìì—´ ì¼ë¶€: {current[i-20:i+20]}\")\n",
    "                break  # ì²« ì°¨ì´ë§Œ í™•ì¸\n",
    "    else:\n",
    "        print(f\"âœ… í•­ëª© 0ê³¼ í•­ëª© {idx}ëŠ” ì™„ì „íˆ ë™ì¼í•©ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f764983",
   "metadata": {},
   "source": [
    "### ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ ë¹„êµ\n",
    "ğŸ” ì„œë¹„ìŠ¤ID & ì„œë¹„ìŠ¤ëª… ê°™ì§€ë§Œ ë‚´ìš©ì´ ë‹¤ë¥¸ ê²½ìš°:   \n",
    "ğŸ” ì„œë¹„ìŠ¤ID ê°™ì§€ë§Œ ì„œë¹„ìŠ¤ëª…ì´ ë‹¤ë¥¸ ê²½ìš°:   \n",
    "ğŸ” ì„œë¹„ìŠ¤ëª… ê°™ì§€ë§Œ ì„œë¹„ìŠ¤IDê°€ ë‹¤ë¥¸ ê²½ìš°:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e53fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# dict: ì„œë¹„ìŠ¤ID -> item ì „ì²´\n",
    "id_to_items = defaultdict(list)\n",
    "for item in data:\n",
    "    sid = item.get(\"ì„œë¹„ìŠ¤ID\")\n",
    "    id_to_items[sid].append(item)\n",
    "\n",
    "# dict: ì„œë¹„ìŠ¤ëª… -> ì„œë¹„ìŠ¤ID ë¦¬ìŠ¤íŠ¸\n",
    "name_to_ids = defaultdict(list)\n",
    "for item in data:\n",
    "    name_to_ids[item[\"ì„œë¹„ìŠ¤ëª…\"]].append(item[\"ì„œë¹„ìŠ¤ID\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 1ï¸âƒ£ ì„œë¹„ìŠ¤IDëŠ” ê°™ê³  ì„œë¹„ìŠ¤ëª…ë„ ê°™ì§€ë§Œ ë‚´ìš©ì´ ë‹¤ë¥¸ ê²½ìš°\n",
    "# -----------------------------\n",
    "diff_content_same_id = []\n",
    "for sid, items in id_to_items.items():\n",
    "    if len(items) > 1:\n",
    "        base = json.dumps(items[0], sort_keys=True, ensure_ascii=False)\n",
    "        for other in items[1:]:\n",
    "            if json.dumps(other, sort_keys=True, ensure_ascii=False) != base:\n",
    "                diff_content_same_id.append(sid)\n",
    "                break\n",
    "\n",
    "print(f\"ğŸ” ì„œë¹„ìŠ¤ID & ì„œë¹„ìŠ¤ëª… ê°™ì§€ë§Œ ë‚´ìš©ì´ ë‹¤ë¥¸ ê²½ìš°: {len(diff_content_same_id)}ê°œ\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2ï¸âƒ£ ì„œë¹„ìŠ¤IDëŠ” ê°™ì€ë° ì„œë¹„ìŠ¤ëª…ì´ ë‹¤ë¥¸ ê²½ìš°\n",
    "# -----------------------------\n",
    "diff_name_same_id = []\n",
    "for sid, items in id_to_items.items():\n",
    "    names = {item.get(\"ì„œë¹„ìŠ¤ëª…\") for item in items}\n",
    "    if len(names) > 1:\n",
    "        diff_name_same_id.append((sid, list(names)))\n",
    "\n",
    "print(f\"ğŸ” ì„œë¹„ìŠ¤ID ê°™ì§€ë§Œ ì„œë¹„ìŠ¤ëª…ì´ ë‹¤ë¥¸ ê²½ìš°: {len(diff_name_same_id)}ê°œ\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3ï¸âƒ£ ì„œë¹„ìŠ¤ëª…ì€ ê°™ì€ë° ì„œë¹„ìŠ¤IDê°€ ë‹¤ë¥¸ ê²½ìš°\n",
    "# -----------------------------\n",
    "same_name_diff_id = []\n",
    "for name, sids in name_to_ids.items():\n",
    "    if len(set(sids)) > 1:\n",
    "        same_name_diff_id.append((name, list(set(sids))))\n",
    "\n",
    "print(f\"ğŸ” ì„œë¹„ìŠ¤ëª… ê°™ì§€ë§Œ ì„œë¹„ìŠ¤IDê°€ ë‹¤ë¥¸ ê²½ìš°: {len(same_name_diff_id)}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466682c",
   "metadata": {},
   "source": [
    "## âœ… ì„œë¹„ìŠ¤ í†µí•© ê¸°ì¤€ ë° ë°©ì‹ ì •ë¦¬\n",
    "\n",
    "ìœ„ì—ì„œ ì„œë¹„ìŠ¤IDê°€ ê°™ì§€ë§Œ ì„œë¹„ìŠ¤ëª…ì´ ë‹¤ë¥¸ ê²½ìš°ëŠ” ì¡´ì¬í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— í†µí•©ì€ ì„œë¹„ìŠ¤ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ì•„ ë³´ì„.\n",
    "\n",
    "| êµ¬ë¶„ | ì¡°ê±´ | ì²˜ë¦¬ ë°©ì‹ | í†µí•© ë°©ì‹ ìƒì„¸ |\n",
    "|------|------|------------|----------------|\n",
    "| 1. ì™„ì „ ì¤‘ë³µ ì œê±° | `ì„œë¹„ìŠ¤ëª…`, `ì„œë¹„ìŠ¤ID`, ë‚´ìš©ì´ ëª¨ë‘ ë™ì¼ | í•˜ë‚˜ë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ ì œê±° | ì¤‘ë³µ í•­ëª© ì œê±° (ë‚´ìš©ê¹Œì§€ ì™„ì „íˆ ë™ì¼í•œ ê²½ìš°) |\n",
    "| 2. `ì„œë¹„ìŠ¤ëª…`, `ì„œë¹„ìŠ¤ID`ëŠ” ê°™ì§€ë§Œ ì„¸ë¶€ ë‚´ìš© ë‹¤ë¦„ | ë™ì¼í•œ ì„œë¹„ìŠ¤ë¡œ íŒë‹¨ | í•˜ë‚˜ë¡œ ë³‘í•© | - ëŒ€í‘œ IDì™€ ì´ë¦„ ê·¸ëŒ€ë¡œ ìœ ì§€<br>- `ì¡°ê±´` í•„ë“œë§Œ ë‹¤ë¥´ë©´ ì¡°ê±´ ë³‘í•©<br>- ë‹¤ë¥¸ í•„ë“œë„ ë‹¤ë¥¼ ê²½ìš°, ë¬¸ìì—´ì€ `||`ë¡œ ë³‘í•©, dictëŠ” í‚¤ ë‹¨ìœ„ ë³‘í•© |\n",
    "| 3. ì„œë¹„ìŠ¤ëª… ë™ì¼, ì„œë¹„ìŠ¤ID ë‹¤ë¦„ | ë™ì¼í•œ ì„œë¹„ìŠ¤ë¡œ íŒë‹¨ | í•˜ë‚˜ì˜ í•­ëª©ìœ¼ë¡œ ë³‘í•© | - ëŒ€í‘œ IDëŠ” ì²« ë²ˆì§¸ í•­ëª©ì˜ `ì„œë¹„ìŠ¤ID`ë¡œ ì„¤ì •<br>- ë¬¸ìì—´ í•„ë“œ: ì„œë¡œ ë‹¤ë¥´ë©´ `||`ë¡œ ë³‘í•©<br>- ë¦¬ìŠ¤íŠ¸: ì¤‘ë³µ ì œê±° í›„ ë³‘í•©<br>- `dict` (ì˜ˆ: `ì¡°ê±´`, `ëŒ€ìƒì—°ë ¹`): key ê¸°ì¤€ ë³‘í•©<br>- ìˆ«ì ë²”ìœ„ (`ëŒ€ìƒì—°ë ¹` ë“±): min/maxë¡œ ë³‘í•© |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                           # JSON ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ëª¨ë“ˆ\n",
    "from collections import defaultdict   # ê¸°ë³¸ê°’ì´ ìˆëŠ” dict ìƒì„±ìš©\n",
    "from pathlib import Path              # ê²½ë¡œ ê´€ë¦¬ë¥¼ ìœ„í•œ Path ê°ì²´\n",
    "from copy import deepcopy             # ê°ì²´ ê¹Šì€ ë³µì‚¬ìš© ëª¨ë“ˆ\n",
    "\n",
    "# JSON íŒŒì¼ì„ ì—´ê³  ë°ì´í„° ë¡œë“œ\n",
    "with open(\"data/combined_service_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)              # JSON íŒŒì¼ì„ Python ê°ì²´ë¡œ ë¡œë“œ\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì§‘í•© ë° ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "seen = set()                         # (ì„œë¹„ìŠ¤ID, ì„œë¹„ìŠ¤ëª…, ì „ì²´ë‚´ìš©)ì„ ì €ì¥í•  set\n",
    "deduped = []                         # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "# ì™„ì „ ë™ì¼ í•­ëª© ì œê±° (ì„œë¹„ìŠ¤ID, ì„œë¹„ìŠ¤ëª…, ë‚´ìš©ê¹Œì§€ ì™„ì „íˆ ë™ì¼)\n",
    "for item in data:\n",
    "    key = (item[\"ì„œë¹„ìŠ¤ID\"], item[\"ì„œë¹„ìŠ¤ëª…\"])                       # ì„œë¹„ìŠ¤IDì™€ ì„œë¹„ìŠ¤ëª…ì„ ë¬¶ì–´ì„œ í‚¤ ìƒì„±\n",
    "    serialized = json.dumps(item, sort_keys=True, ensure_ascii=False) # í•­ëª© ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ\n",
    "    if (key, serialized) not in seen:                                # ì¤‘ë³µë˜ì§€ ì•Šì•˜ë‹¤ë©´\n",
    "        seen.add((key, serialized))                                  # ì§‘í•©ì— ì¶”ê°€\n",
    "        deduped.append(item)                                         # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "\n",
    "# ì„œë¹„ìŠ¤ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ í•­ëª©ë“¤ì„ ê·¸ë£¹í™”\n",
    "name_to_items = defaultdict(list)      # ì„œë¹„ìŠ¤ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "for item in deduped:\n",
    "    name_to_items[item[\"ì„œë¹„ìŠ¤ëª…\"]].append(item)   # ì„œë¹„ìŠ¤ëª… ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì— í•­ëª© ì¶”ê°€\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í•­ëª©ì„ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
    "def merge_items(items):\n",
    "    base = deepcopy(items[0])          # ì²« ë²ˆì§¸ í•­ëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© (ê¹Šì€ ë³µì‚¬)\n",
    "    for other in items[1:]:            # ë‘ ë²ˆì§¸ í•­ëª©ë¶€í„° ë°˜ë³µ\n",
    "        for key, val in other.items(): # ê° í‚¤-ê°’ì— ëŒ€í•´\n",
    "            if key not in base or base[key] == val: # ê°’ì´ ë™ì¼í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ íŒ¨ìŠ¤\n",
    "                continue\n",
    "            if isinstance(val, str) and isinstance(base[key], str): # ë¬¸ìì—´ íƒ€ì…ì¼ ê²½ìš°\n",
    "                parts = set(base[key].split(\"||\")) | set(val.split(\"||\")) # ì¤‘ë³µ ì œê±°í•œ ì§‘í•© ìƒì„±\n",
    "                base[key] = \"||\".join(sorted(parts))              # ë‹¤ì‹œ || ë¡œ ì—°ê²°\n",
    "            elif isinstance(val, list) and isinstance(base[key], list): # ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš°\n",
    "                base[key] = list(set(base[key]) | set(val))       # ì§‘í•©ìœ¼ë¡œ ë³‘í•© í›„ ë¦¬ìŠ¤íŠ¸ ë³€í™˜\n",
    "            elif isinstance(val, dict) and isinstance(base[key], dict): # ë”•ì…”ë„ˆë¦¬ì¼ ê²½ìš°\n",
    "                merged = base[key].copy()                         # ê¸°ì¤€ê°’ ë³µì‚¬\n",
    "                for k, v in val.items():                          # ë³‘í•© ëŒ€ìƒ ë”•ì…”ë„ˆë¦¬ ìˆœíšŒ\n",
    "                    if k in merged and merged[k] != v:           # í‚¤ê°€ ì¡´ì¬í•˜ê³  ê°’ì´ ë‹¤ë¥¼ ë•Œ\n",
    "                        merged[k] = merged[k] or v               # ë‘˜ ì¤‘ True ìš°ì„ \n",
    "                    else:\n",
    "                        merged[k] = v                            # ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€\n",
    "                base[key] = merged                                # ë³‘í•©ëœ ê²°ê³¼ ì €ì¥\n",
    "            else:\n",
    "                base[key] = f\"{base[key]}||{val}\"                # ê·¸ ì™¸ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë³‘í•©\n",
    "    return base                                                  # ë³‘í•©ëœ ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "# ë³‘í•© ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "final_data = []                      # ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "merged_log = []                      # ë³‘í•©ëœ í•­ëª© ë¡œê·¸ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "# ê° ì„œë¹„ìŠ¤ëª… ê·¸ë£¹ì— ëŒ€í•´ ì²˜ë¦¬\n",
    "for name, items in name_to_items.items():\n",
    "    service_ids = {item[\"ì„œë¹„ìŠ¤ID\"] for item in items} # í•´ë‹¹ ì„œë¹„ìŠ¤ëª…ì˜ ì„œë¹„ìŠ¤ID ì§‘í•© ìƒì„±\n",
    "    if len(service_ids) == 1:                         # IDê°€ í•˜ë‚˜ë©´ ì¤‘ë³µì´ ì•„ë‹˜\n",
    "        final_data.append(items[0])                   # ê·¸ëŒ€ë¡œ ì¶”ê°€\n",
    "    else:\n",
    "        merged = merge_items(items)                   # ì—¬ëŸ¬ IDê°€ ì¡´ì¬í•˜ë©´ ë³‘í•© ìˆ˜í–‰\n",
    "        merged_log.append((name, list(service_ids)))  # ë³‘í•©ëœ ì„œë¹„ìŠ¤ëª…ê³¼ ID ê¸°ë¡\n",
    "        final_data.append(merged)                     # ë³‘í•©ëœ ê²°ê³¼ ì €ì¥\n",
    "\n",
    "\n",
    "# ë³‘í•© ë¡œê·¸ ì¶œë ¥\n",
    "print(f\"âœ… ìµœì¢… í•­ëª© ìˆ˜: {len(final_data)}ê°œ\")                      # ìµœì¢… í•­ëª© ìˆ˜ ì¶œë ¥\n",
    "print(f\"ğŸ” ë³‘í•©ëœ ì„œë¹„ìŠ¤ ìˆ˜: {len(merged_log)}ê°œ\")                 # ë³‘í•©ëœ ì„œë¹„ìŠ¤ ê°œìˆ˜ ì¶œë ¥\n",
    "for name, ids in merged_log[:10]:                               # ìµœëŒ€ 10ê°œ ë¡œê·¸ ì¶œë ¥\n",
    "    print(f\"ğŸ”¹ ì„œë¹„ìŠ¤ëª…: {name} / ë³‘í•©ëœ ì„œë¹„ìŠ¤ID: {ids}\")        # ì„œë¹„ìŠ¤ëª…ê³¼ ë³‘í•©ëœ ID ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fce251",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³‘í•©ëœ ì‹¤ì œ ì˜ˆì‹œ ì¶œë ¥\n",
    "print(\"\\nğŸ“Œ ë³‘í•©ëœ ì„œë¹„ìŠ¤ ì˜ˆì‹œ (ìµœëŒ€ 3ê°œ):\\n\")\n",
    "for name, ids in merged_log[:3]:\n",
    "    print(f\"ğŸ” ì„œë¹„ìŠ¤ëª…: {name}\")\n",
    "    print(f\"ğŸ“Œ ë³‘í•©ëœ ì„œë¹„ìŠ¤ID ëª©ë¡: {ids}\\n\")\n",
    "\n",
    "    # ë³‘í•© ê²°ê³¼ ë³´ì—¬ì£¼ê¸°\n",
    "    for item in final_data:\n",
    "        if item[\"ì„œë¹„ìŠ¤ëª…\"] == name:\n",
    "            print(json.dumps(item, ensure_ascii=False, indent=2))\n",
    "            print(\"=\"*80)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.parse\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… í•­ìƒ RAG í´ë”ì˜ .envì—ì„œ ë¡œë“œë˜ë„ë¡ ì„¤ì •\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # í˜„ì¬ ì‘ì—… í´ë”ì˜ ë¶€ëª¨ = RAG\n",
    "env_path = os.path.join(base_dir, \".env\")  # RAG/.env\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "# âœ… í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì˜ˆì™¸ ì²˜ë¦¬\n",
    "GOV24_API_KEY = os.getenv(\"GOV24_API_KEY\")\n",
    "if GOV24_API_KEY is None:\n",
    "    raise ValueError(\"âŒ .envì—ì„œ 'GOV24_API_KEY'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# âœ… URL ì¸ì½”ë”©\n",
    "encoded_key = urllib.parse.quote(GOV24_API_KEY, safe='')\n",
    "\n",
    "# âœ… í™•ì¸ ì¶œë ¥ (ì„ íƒ)\n",
    "print(\"ğŸ”‘ ì¸ì½”ë”©ëœ key:\", encoded_key[:10] + \"...\" if encoded_key else \"âŒ ì¸ì½”ë”© ì‹¤íŒ¨\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
