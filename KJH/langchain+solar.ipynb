{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì „ì²´ êµ¬ì¡° ìš”ì•½\n",
    "1. ë¬¸ì„œ ë¡œë“œ (JSON, TXT ë“±)\n",
    "2. ì²­í¬ ë¶„í•  (TextSplitter)\n",
    "3. ì„ë² ë”© (Upstage Embedding ì‚¬ìš©) + ë²¡í„° ì €ì¥ì†Œ (FAISS)\n",
    "4. ì§ˆë¬¸ ì…ë ¥ â†’ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "5. LLMì—ê²Œ prompt ìƒì„± â†’ ë‹µë³€ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¬¸ì„œ ë¡œë“œ\n",
    "### json ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"../EDA/data\")\n",
    "data_path = os.path.join(DATA_DIR, \"combined_service_data_merged.json\")\n",
    "prev_path = os.path.join(DATA_DIR, \"combined_service_data_merged_prev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ì „ì²´ ì„œë¹„ìŠ¤ ê°œìˆ˜: 8850ê°œ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# JSON ë¡œë“œ ë° ê°œìˆ˜ ì¶œë ¥\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“¦ ì „ì²´ ì„œë¹„ìŠ¤ ê°œìˆ˜: {len(data)}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ langchain ë¬¸ì„œë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ì¶”ê°€ëœ ë¬¸ì„œ: 0ê°œ\n",
      "ğŸ”„ ìˆ˜ì •ëœ ë¬¸ì„œ: 0ê°œ\n",
      "âŒ ì‚­ì œëœ ë¬¸ì„œ: 0ê°œ\n",
      "âœ… LangChain ë¬¸ì„œ ìƒì„± ì™„ë£Œ: 0ê°œ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# ğŸ”¹ JSON ë¡œë“œ (new)\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    new_data = json.load(f)\n",
    "new_dict = {item[\"ì„œë¹„ìŠ¤ID\"]: item for item in new_data}\n",
    "\n",
    "# ğŸ”¹ JSON ë¡œë“œ (prev)\n",
    "if os.path.exists(prev_path):\n",
    "    with open(prev_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prev_data = json.load(f)\n",
    "    prev_dict = {item[\"ì„œë¹„ìŠ¤ID\"]: item for item in prev_data}\n",
    "else:\n",
    "    prev_data = []\n",
    "    prev_dict = {}\n",
    "\n",
    "    \n",
    "# ë³€ê²½ ê°ì§€\n",
    "added, updated, deleted = [], [], []\n",
    "\n",
    "# new_dictì˜ ëª¨ë“  ì„œë¹„ìŠ¤ID(sid)ì™€ í•´ë‹¹ ë°ì´í„°(item)ì— ëŒ€í•´ ë°˜ë³µ\n",
    "for sid, item in new_dict.items():\n",
    "    # ì´ì „ ë°ì´í„°(prev_dict)ì— í˜„ì¬ ì„œë¹„ìŠ¤IDê°€ ì—†ìœ¼ë©´ â†’ ì‹ ê·œ ì¶”ê°€ëœ í•­ëª©ìœ¼ë¡œ ê°„ì£¼\n",
    "    if sid not in prev_dict:\n",
    "        added.append(item)  # ì¶”ê°€ ëª©ë¡ì— í¬í•¨\n",
    "    # ì´ì „ì—ë„ ì¡´ì¬í–ˆì§€ë§Œ ë‚´ìš©ì´ ë‹¤ë¥¸ ê²½ìš° â†’ ìˆ˜ì •ëœ í•­ëª©ìœ¼ë¡œ ê°„ì£¼\n",
    "    elif json.dumps(item, sort_keys=True, ensure_ascii=False) != json.dumps(prev_dict[sid], sort_keys=True, ensure_ascii=False):\n",
    "        updated.append(item)  # ìˆ˜ì • ëª©ë¡ì— í¬í•¨\n",
    "\n",
    "# ì´ì „ ë°ì´í„°(prev_dict)ì—ë§Œ ìˆê³  í˜„ì¬ ë°ì´í„°(new_dict)ì—ëŠ” ì—†ëŠ” ì„œë¹„ìŠ¤IDë¥¼ ì°¾ìŒ\n",
    "for sid in prev_dict:\n",
    "    # í˜„ì¬ ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ â†’ ì‚­ì œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼\n",
    "    if sid not in new_dict:\n",
    "        deleted.append(prev_dict[sid])  # ì‚­ì œ ëª©ë¡ì— í¬í•¨\n",
    "\n",
    "\n",
    "print(f\"ğŸ†• ì¶”ê°€ëœ ë¬¸ì„œ: {len(added)}ê°œ\")\n",
    "print(f\"ğŸ”„ ìˆ˜ì •ëœ ë¬¸ì„œ: {len(updated)}ê°œ\")\n",
    "print(f\"âŒ ì‚­ì œëœ ë¬¸ì„œ: {len(deleted)}ê°œ\")\n",
    "\n",
    "# âœ… ì„ë² ë”© ëŒ€ìƒ: ì¶”ê°€ + ìˆ˜ì • ë¬¸ì„œë§Œ\n",
    "target_docs = added + updated\n",
    "\n",
    "# LangChain ë¬¸ì„œ ë³€í™˜\n",
    "documents = []\n",
    "for item in target_docs:\n",
    "    ì¡°ê±´_íƒœê·¸ = [k for k, v in item.get(\"ì¡°ê±´\", {}).items() if v]\n",
    "\n",
    "    content = f\"\"\"\n",
    "ì„œë¹„ìŠ¤ëª…: {item.get('ì„œë¹„ìŠ¤ëª…')}\n",
    "ì„œë¹„ìŠ¤ëª©ì : {item.get('ì„œë¹„ìŠ¤ëª©ì ')}\n",
    "ì§€ì›ëŒ€ìƒ: {item.get('ì§€ì›ëŒ€ìƒ')}\n",
    "ì§€ì›ë‚´ìš©: {item.get('ì§€ì›ë‚´ìš©')}\n",
    "ì‹ ì²­ë°©ë²•: {item.get('ì‹ ì²­ë°©ë²•')}\n",
    "ì‹ ì²­ê¸°í•œ: {item.get('ì‹ ì²­ê¸°í•œ')}\n",
    "ì„ ì •ê¸°ì¤€: {item.get('ì„ ì •ê¸°ì¤€')}\n",
    "êµ¬ë¹„ì„œë¥˜: {item.get('êµ¬ë¹„ì„œë¥˜')}\n",
    "ì†Œê´€ê¸°ê´€: {item.get('ì†Œê´€ê¸°ê´€ëª…')}\n",
    "ë¬¸ì˜ì²˜: {item.get('ë¬¸ì˜ì²˜')}\n",
    "ì˜¨ë¼ì¸ì‹ ì²­URL: {item.get('ì˜¨ë¼ì¸ì‹ ì²­ì‚¬ì´íŠ¸URL')}\n",
    "ë²•ë ¹: {item.get('ë²•ë ¹')}\n",
    "í•´ë‹¹ ì¡°ê±´: {', '.join(ì¡°ê±´_íƒœê·¸)}\n",
    "\"\"\"\n",
    "\n",
    "    doc = Document(\n",
    "        page_content=content.strip(),\n",
    "        metadata={\n",
    "            \"ì„œë¹„ìŠ¤ID\": item.get(\"ì„œë¹„ìŠ¤ID\"),\n",
    "            \"ì„œë¹„ìŠ¤ëª…\": item.get(\"ì„œë¹„ìŠ¤ëª…\"),\n",
    "            \"ì¡°ê±´\": item.get(\"ì¡°ê±´\", {}),\n",
    "            \"ì›ë³¸\": item\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"âœ… LangChain ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {len(documents)}ê°œ\")\n",
    "if documents:\n",
    "    print(\"ğŸ” ì˜ˆì‹œ ë¬¸ì„œ ë‚´ìš©:\\n\", documents[0].page_content[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… new_data ê°œìˆ˜: 8850\n",
      "âœ… prev_data ê°œìˆ˜: 8850\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… new_data ê°œìˆ˜:\", len(new_data))\n",
    "print(\"âœ… prev_data ê°œìˆ˜:\", len(prev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì²­í¬ ë¶„í• \n",
    "ë¬¸ììˆ˜ ê¸°ë°˜ê³¼ í† í° ê¸°ë°˜ìœ¼ë¡œ ë‚˜ë‰˜ëŠ”ë° ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ëŒë¦´ ê²ƒ.\n",
    "ë¬¸ì¥ ë‹¨ìœ„ ì˜ë¯¸ ë³´ì¡´ì´ ë” ì¤‘ìš”í•˜ë‹¤ íŒë‹¨ë˜ë©´ ë¬¸ììˆ˜ ê¸°ë°˜ / ë¹„ìš© ì •í™•ë„, ì…ë ¥ ì œí•œ ê´€ë¦¬ ì¤‘ìš”í•˜ë‹¤ íŒë‹¨ë˜ë©´ í† í° ê¸°ë°˜\n",
    "\n",
    "### ë¬¸ììˆ˜ ê¸°ë°˜ ì²­í¬ ë¶„í• \n",
    "chunk_size=500 â†’ ì²­í¬ í•˜ë‚˜ì˜ page_content ê¸¸ì´ê°€ ìµœëŒ€ 500ìë¡œ ì œí•œë¨\n",
    "\n",
    "chunk_overlap=100 â†’ ì´ì „ ì²­í¬ ë 100ì â†’ ë‹¤ìŒ ì²­í¬ ì‹œì‘ì— ê²¹ì³ì„œ ë“¤ì–´ê°\n",
    "\n",
    "Recursive â†’ ì¤„ë°”ê¿ˆ(\\n) â†’ ë„ì–´ì“°ê¸°( ) â†’ ì•„ë¬´ ë°ì„œë‚˜ (\"\") ìˆœì„œë¡œ ë¶„í•  ì‹œë„\n",
    "â†’ ê°€ëŠ¥í•œ í•œ ë¬¸ì¥ ë‹¨ìœ„ ë˜ëŠ” ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ëŠìœ¼ë ¤ ë…¸ë ¥í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ë¬¸ì„œ ë‚´ìš©ì— ë³€í™”ê°€ ì—†ì–´ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # ë¬¸ì ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸° import\n",
    "\n",
    "# ë¬¸ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• ê¸° ì •ì˜\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,       # ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "    chunk_overlap=100     # ì²­í¬ ê°„ ì¤‘ë³µ ë¬¸ì ìˆ˜ (ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ ì‚¬ìš©)\n",
    ")\n",
    "\n",
    "# ê¸°ì¡´ì— ë§Œë“  LangChain ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (`documents`)ì— ëŒ€í•´ ë¶„í•  ìˆ˜í–‰\n",
    "split_docs = text_splitter.split_documents(documents)  # ê° Documentì˜ page_contentë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• \n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "if split_docs:\n",
    "    print(f\"âœ… ì „ì²´ ì²­í¬ ìˆ˜: {len(split_docs)}\")\n",
    "    print(\"ğŸ” ì²« ë²ˆì§¸ ì²­í¬ ì˜ˆì‹œ:\\n\", split_docs[0].page_content)\n",
    "else:\n",
    "    print(\"âš ï¸ ë¬¸ì„œ ë‚´ìš©ì— ë³€í™”ê°€ ì—†ì–´ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í† í° ê¸°ë°˜ ì²­í¬ ë¶„í• \n",
    "chunk_size: ê° ë¬¸ì„œë¥¼ ëª‡ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆŒì§€ ê²°ì •í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„°.\n",
    "\n",
    "chunk_overlap: ë‹¤ìŒ ì²­í¬ê°€ ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ ì¼ë¶€ë¥¼ í¬í•¨í•˜ê²Œ í•´ì„œ ë¬¸ë§¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì£¼ê¸° ìœ„í•œ ì¥ì¹˜.\n",
    "\n",
    "cl100k_base: OpenAIì˜ ìµœì‹  ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í† í¬ë‚˜ì´ì €. Solarì˜ ì„ë² ë”©ê³¼ í† í° êµ¬ì¡°ê°€ ìœ ì‚¬í•˜ë‹¤ê³  ì•Œë ¤ì ¸ ìˆìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ë¬¸ì„œ ë‚´ìš©ì— ë³€í™”ê°€ ì—†ì–´ í† í° ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter  # í† í° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "from langchain_openai import OpenAIEmbeddings  # ì„ë² ë”© ëª¨ë¸ (í† í¬ë‚˜ì´ì € ê³µìœ )\n",
    "\n",
    "# OpenAI ê¸°ì¤€: text-embedding-ada-002ëŠ” max 8191 tokens\n",
    "# ì•ˆì „í•˜ê²Œ 512 ~ 1024 ë‹¨ìœ„ë¡œ ì²­í¬ ë‚˜ëˆ„ëŠ” ê²Œ ì¼ë°˜ì \n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=1000,        # í•œ ì²­í¬ë‹¹ ìµœëŒ€ í† í° ìˆ˜\n",
    "    chunk_overlap=150       # ì¤‘ë³µ í† í° ìˆ˜ (ë¬¸ë§¥ ìœ ì§€ìš©) chunk_overlap ê¸°ìˆ  ì ìš©\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ë¶„í• \n",
    "token_split_docs = token_splitter.split_documents(documents)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "if token_split_docs:\n",
    "    print(f\"âœ… í† í° ê¸°ë°˜ ì²­í¬ ìˆ˜: {len(token_split_docs)}\")\n",
    "    print(\"ğŸ” ì˜ˆì‹œ ì²­í¬:\\n\", token_split_docs[0].page_content)\n",
    "else:\n",
    "    print(\"âš ï¸ ë¬¸ì„œ ë‚´ìš©ì— ë³€í™”ê°€ ì—†ì–´ í† í° ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar Embedding ë¹„ìš© ê³„ì‚° ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” í† í° ìˆ˜ ê³„ì‚° ì¤‘: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ì´ ì²­í¬ ìˆ˜: 0\n",
      "ğŸ”¢ ì´ í† í° ìˆ˜: 0 tokens\n",
      "ğŸ’µ ì˜ˆìƒ ë¹„ìš©: $0.0000 USD\n",
      "ğŸ’° ì˜ˆìƒ ë¹„ìš©: ì•½ 0ì› (í™˜ìœ¨: 1350ì›/USD)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken  # í† í° ê³„ì‚°ìš©\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. í† í¬ë‚˜ì´ì € ë¡œë“œ (SolarëŠ” cl100k_base ê³„ì—´ê³¼ ê±°ì˜ ë™ì¼)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# 2. ì „ì²´ í† í° ìˆ˜ ê³„ì‚°\n",
    "total_tokens = 0\n",
    "for doc in tqdm(token_split_docs, desc=\"ğŸ” í† í° ìˆ˜ ê³„ì‚° ì¤‘\"):       # ê³„ì‚°í•˜ê³  ì‹¶ì€ ì²­í¬\n",
    "    tokens = tokenizer.encode(doc.page_content)\n",
    "    total_tokens += len(tokens)\n",
    "\n",
    "# 3. Solar ì‹¤ì œ ìš”ìœ¨ ê¸°ì¤€ ë‹¨ê°€ ì„¤ì • (1,000 tokens = $0.0000973)\n",
    "usd_per_1000_tokens = 0.0000973\n",
    "estimated_cost_usd = (total_tokens / 1000) * usd_per_1000_tokens\n",
    "\n",
    "# 4. í•œí™” í™˜ìœ¨ë¡œ ë³€í™˜ (ì˜ˆ: 1 USD = 1350ì› ê°€ì •)\n",
    "exchange_rate = 1350\n",
    "estimated_cost_krw = estimated_cost_usd * exchange_rate\n",
    "\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nğŸ“Š ì´ ì²­í¬ ìˆ˜: {len(token_split_docs)}\")\n",
    "print(f\"ğŸ”¢ ì´ í† í° ìˆ˜: {total_tokens:,} tokens\")\n",
    "print(f\"ğŸ’µ ì˜ˆìƒ ë¹„ìš©: ${estimated_cost_usd:.4f} USD\")\n",
    "print(f\"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ì•½ {estimated_cost_krw:,.0f}ì› (í™˜ìœ¨: {exchange_rate}ì›/USD)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì„ë² ë”© (Upstage Embedding ì‚¬ìš©) + ë²¡í„° ì €ì¥ì†Œ (FAISS)\n",
    "### API ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” API KEY: ë¶ˆëŸ¬ì˜´\n",
      "ğŸŒ API URL: https://api.upstage.ai/v1/embeddings\n",
      "ğŸ“ base_dir: c:\\Users\\jihu6\\code\\RAG\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# âœ… RAG/.env ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ë¶€ëª¨(RAG)\n",
    "env_path = os.path.join(base_dir, \".env\")  # RAG/.env\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# âœ… í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "UPSTAGE_API_URL = os.getenv(\"UPSTAGE_API_URL\")\n",
    "\n",
    "# âœ… ê²°ê³¼ í™•ì¸\n",
    "print(\"ğŸ” API KEY:\", \"ë¶ˆëŸ¬ì˜´\" if UPSTAGE_API_KEY else \"âŒ ì—†ìŒ\")\n",
    "print(\"ğŸŒ API URL:\", UPSTAGE_API_URL if UPSTAGE_API_URL else \"âŒ ì—†ìŒ\")\n",
    "print(\"ğŸ“ base_dir:\", base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLAR APIë¡œ ì„ë² ë”© + FAISSì— ë²¡í„° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import time  # ìš”ì²­ ê°„ ê°„ê²© ì¡°ì •ìš© (ì„ íƒ)\n",
    "import requests\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "\n",
    "class UpstageEmbeddings(Embeddings):\n",
    "    def __init__(self, api_key: str, api_url: str, batch_size: int = 64):\n",
    "        self.api_key = api_key  # API í‚¤ ì €ì¥\n",
    "        self.api_url = api_url  # ìš”ì²­ ë³´ë‚¼ URL ì €ì¥\n",
    "        self.batch_size = batch_size  # í•œ ë²ˆì— ë³´ë‚¼ í…ìŠ¤íŠ¸ ê°œìˆ˜\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        all_embeddings = []\n",
    "\n",
    "        for i in tqdm(range(0, len(texts), self.batch_size), desc=\"ğŸ”„ Solar ì„ë² ë”© ì¤‘\"):\n",
    "            batch = texts[i:i + self.batch_size]\n",
    "\n",
    "            # ğŸ‘‡ ë””ë²„ê¹…ìš©: ë¬¸ìì—´ ì•„ë‹Œ í•­ëª© ê²€ì‚¬\n",
    "            if not all(isinstance(t, str) for t in batch):\n",
    "                print(\"â—ë¬¸ìì—´ì´ ì•„ë‹Œ ë°ì´í„°ê°€ í¬í•¨ë¨:\")\n",
    "                for t in batch:\n",
    "                    print(type(t), \"â†’\", repr(t)[:100])\n",
    "\n",
    "            # âœ… Solar APIì— í•„ìš”í•œ model í•„ë“œ ì¶”ê°€!\n",
    "            payload = {\n",
    "                \"input\": batch,\n",
    "                \"model\": \"embedding-query\"  # ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•¨\n",
    "            }\n",
    "\n",
    "            response = requests.post(self.api_url, headers=headers, json=payload)\n",
    "\n",
    "            # ì—ëŸ¬ ì¶œë ¥\n",
    "            if response.status_code != 200:\n",
    "                print(\"âŒ ì—ëŸ¬ ì‘ë‹µ ìƒíƒœ:\", response.status_code)\n",
    "                print(\"âŒ ì—ëŸ¬ ì‘ë‹µ ë³¸ë¬¸:\", response.text)\n",
    "\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            all_embeddings.extend([item[\"embedding\"] for item in result[\"data\"]])\n",
    "            time.sleep(0.1)  # ìš”ì²­ ë„ˆë¬´ ë¹ ë¥´ê²Œ ë³´ë‚´ì§€ ì•Šë„ë¡ ë”œë ˆì´\n",
    "\n",
    "        return all_embeddings\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ì„ë² ë”©í•  ë¬¸ì„œê°€ ì—†ì–´ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ FAISS ë° ì„ë² ë”© í´ë˜ìŠ¤ ì„í¬íŠ¸\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# ğŸ”¹ Upstage ì„ë² ë”© ê°ì²´ ìƒì„± (ì•ì„œ ë§Œë“  ì‚¬ìš©ì ì •ì˜ í´ë˜ìŠ¤ ì‚¬ìš©)\n",
    "embedding = UpstageEmbeddings(\n",
    "    api_key=UPSTAGE_API_KEY,  # .envì—ì„œ ë¶ˆëŸ¬ì˜¨ API í‚¤\n",
    "    api_url=UPSTAGE_API_URL,  # .envì—ì„œ ë¶ˆëŸ¬ì˜¨ API URL\n",
    "    batch_size=64             # í•œ ë²ˆì— 64ê°œì”© ì²˜ë¦¬\n",
    ")\n",
    "\n",
    "# ğŸ”¹ ì²­í¬ê°€ ì¡´ì¬í•  ê²½ìš°ì—ë§Œ FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥\n",
    "if token_split_docs:\n",
    "    db = FAISS.from_documents(token_split_docs, embedding)  # ë¬¸ì„œ ì„ë² ë”© í›„ FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "    db.save_local(\"faiss_index\")  # ì¸ë±ìŠ¤ë¥¼ ë¡œì»¬ ë””ë ‰í† ë¦¬ì— ì €ì¥\n",
    "    print(\"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì„ë² ë”©í•  ë¬¸ì„œê°€ ì—†ì–´ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì§ˆë¬¸ ì…ë ¥ â†’ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë²¡í„° ë°ì´í„° ë² ì´ìŠ¤ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… allow_dangerous_deserialization=True ì¶”ê°€\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings=embedding,\n",
    "    allow_dangerous_deserialization=True  # âœ… Pickle ë¡œë“œ í—ˆìš©\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²€ìƒ‰í•  ì§ˆë¬¸ ì…ë ¥ & 5 íšŒê¹Œì§€ ì±„íŒ… ê¸°ì–µ\n",
    "Ramì—ë§Œ ì €ì¥ë˜ë„ë¡ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰í•  ì§ˆë¬¸ ì˜ˆì‹œ\n",
    "query = \"ì²­ë…„ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ì£¼ê±° ì§€ì›ì€ ë­ê°€ ìˆì§€?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Solar ì„ë² ë”© ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 3ê°œ)\n",
    "docs = db.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ë¬¸ì„œ 1\n",
      "ì„œë¹„ìŠ¤ëª…: ì„œìš¸ì‹œ ì²­ë…„ ì›”ì„¸ ì§€ì›\n",
      "ì„œë¹„ìŠ¤ëª©ì : ì²­ë…„ì¸µì˜ ì£¼ê±°ë¹„ ë¶€ë‹´ ì™„í™”ë¥¼ í†µí•œ ì²­ë…„ ì£¼ê±° ìˆ˜ì¤€ í–¥ìƒìœ¼ë¡œ ì‚¬íšŒ ì§„ì…ì„ ë•ê³  ìƒì•  ë‹¤ìŒë‹¨ê³„(ë‚´ ì§‘ ë§ˆë ¨, ê²°í˜¼, ì¶œì‚°, ì–‘ìœ¡)ë¡œì˜ ì„±ì¥ ì§€ì›\n",
      "ì§€ì›ëŒ€ìƒ: â—‹  ì„œìš¸ ì›”ì„¸ ê±°ì£¼ 19ì„¸ ~ 39ì„¸ ì´í•˜ ë¬´ì£¼íƒ ì²­ë…„ 1ì¸ ê°€êµ¬ (ì²­ë…„ì¸ ë™ê±°ì¸ ë° í˜•ì œìë§¤ ìˆëŠ” ê²½ìš° ì‹ ì²­ ê°€ëŠ¥)\n",
      "    - ì†Œë“ ê¸°ì¤€ : ê¸°ì¤€ ì¤‘ìœ„ì†Œë“ 150% ì´í•˜ \n",
      "    - ì¬ì‚° ê¸°ì¤€ : ì¼ë°˜ì¬ì‚° 1ì–µ 3ì²œë§Œì› ì´í•˜, ìë™ì°¨ 2,500ë§Œì› ë¯¸ë§Œ\n",
      "    - ê±°ì£¼ ìš”ê±´ : ì„ì°¨ ë³´ì¦ê¸ˆ 8ì²œë§Œì› ì´í•˜, ì›”ì„¸ 60ë§Œì› ì´í•˜ ê±´ë¬¼ ì›”ì„¸ ê±°ì£¼\n",
      "ì§€ì›ë‚´ìš©: â—‹ ì‚¬ì—… ë‚´ìš© : ìµœëŒ€ 12ê°œì›” ê°„ ì›” 20ë§Œì› ë²”ìœ„ì—ì„œ ì›”ì„¸ ì§€ì›\n",
      "â—‹ ì†Œìš”ì¬ì› : ì‹œë¹„ 100%\n",
      "ì‹ ì²­ë°©ë²•: ì„œìš¸ì£¼ê±°í¬í„¸ : https://housing.seoul.go.kr ì²­ë…„ì›”ì„¸ì§€ì›ë€ì— ì˜¨ë¼ì¸ ì‹ ì²­,ì ‘ìˆ˜\n",
      "ì‹ ì²­ê¸°í•œ: 2025.6ì›”(ì˜ˆì •)\n",
      "ì„ ì •ê¸°ì¤€: None\n",
      "êµ¬ë¹„ì„œë¥˜: í™•ì •ì¼ìê°€ ë‚ ì¸ëœ ì„ëŒ€ì°¨ê³„ì•½ì„œ ì‚¬ë³¸ 1ë¶€, ì›”ì„¸ì´ì²´ ì¦ë¹™ì„œë¥˜\n",
      "ğŸ“Œ ì¡°ê±´ íƒœê·¸: ë‚¨ì„±, ì—¬ì„±, ì¤‘ìœ„ì†Œë“ 0~50%, ì¤‘ìœ„ì†Œë“ 51~75%, ì¤‘ìœ„ì†Œë“ 76~100%, ì¤‘ìœ„ì†Œë“ 101~200%, ì¤‘ìœ„ì†Œë“ 200% ì´ˆê³¼, ì˜ˆë¹„ë¶€ëª¨/ë‚œì„, ì„ì‚°ë¶€, ì¶œì‚°/ì…ì–‘, ë†ì—…ì¸, ì–´ì—…ì¸, ì¶•ì‚°ì—…ì¸, ì„ì—…ì¸, ì´ˆë“±í•™ìƒ, ì¤‘í•™ìƒ, ê³ ë“±í•™ìƒ, ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ, í•´ë‹¹ì‚¬í•­ì—†ìŒ, ê·¼ë¡œì/ì§ì¥ì¸, êµ¬ì§ì/ì‹¤ì—…ì, ì¥ì• ì¸, êµ­ê°€ë³´í›ˆëŒ€ìƒì, ì§ˆë³‘/ì§ˆí™˜ì, 1ì¸ê°€êµ¬\n",
      "--------------------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 2\n",
      "ì„œë¹„ìŠ¤ëª…: ìš¸ì‚° ì²­ë…„ê°€êµ¬ ì£¼ê±°ë¹„ ì§€ì›ì‚¬ì—… ì§€ì› ì‹ ì²­\n",
      "ì„œë¹„ìŠ¤ëª©ì : ì„ì°¨ë£Œ ë“± ì£¼ê±°ë¹„ ì§€ì›ìœ¼ë¡œ ì²­ë…„ì¸µì˜ ì£¼ê±°ì•ˆì • ë° ì§€ì—­ì •ì°©ìœ¼ë¡œ ê²°í˜¼ìœ¨ ì œê³ \n",
      "ì§€ì›ëŒ€ìƒ: - 19ì„¸~39ì„¸ ë¬´ì£¼íƒ ë¯¸í˜¼ ì²­ë…„ê°€êµ¬ ì„¸ëŒ€ì£¼ \n",
      "- ì„ì°¨ë³´ì¦ê¸ˆ 1ì–µì›ì´í•˜ ë° ì›”ì„¸ 50ë§Œì› ì´í•˜ì¸ ì£¼íƒ ê±°ì£¼  \n",
      "- ê¸°ì¤€ ì¤‘ìœ„ì†Œë“ 150% ì´í•˜(ê±´ê°•ë³´í—˜ë£Œ ë‚©ë¶€ ê¸°ì¤€)\n",
      "ì§€ì›ë‚´ìš©: ì›” ì„ì°¨ë£Œë¹„ìš© 10ë§Œì› ì‹¤ë¹„ì§€ê¸‰\n",
      "ì›” ì„ì°¨ë³´ì¦ê¸ˆì´ìë¹„ìš© 5ë§Œì› ì‹¤ë¹„ì§€ê¸‰\n",
      "â€» ì£¼ê±°ê¸‰ì—¬ ìˆ˜ê¸‰ìëŠ” ì œì™¸\n",
      "ì‹ ì²­ë°©ë²•: ì˜¨ë¼ì¸ì‹ ì²­ : https://www.ulsan.go.kr/s/house\n",
      "ì‹ ì²­ê¸°í•œ: ê³µê³ ë¬¸ ì°¸ì¡°\n",
      "ì„ ì •ê¸°ì¤€: None\n",
      "êµ¬ë¹„ì„œë¥˜: â–¡ ì²­ë…„ ì£¼ê±°ë¹„ ì§€ì›ì‚¬ì—… ëŒ€ìƒì ì„ ì • ì‹ ì²­ì„œë¥˜\n",
      "\n",
      " â—‹ ì‹ ì²­ì¸ ì œì¶œì„œë¥˜\n",
      " -ìš¸ì‚° ì²­ë…„ê°€êµ¬ ì£¼ê±°ë¹„ ì§€ì›ì‚¬ì—…(ì‹ ê·œ, ë³€ê²½) ì‹ ì²­ì„œ \n",
      " -ìš¸ì‚° ì²­ë…„ê°€êµ¬ ì£¼ê±°ë¹„ ì§€ì›ì‚¬ì—… ì‹ ì²­ ì„œì•½ì„œ \n",
      " -ê°œì¸ì •ë³´ ì œê³µ ë™ì˜ì„œ \n",
      " -í–‰ì •ì •ë³´ ê³µë™ì´ìš© ì‚¬ì „ë™ì˜ì„œ\n",
      " -ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì„œ(í™•ì •ì¼ì ë‚ ì¸) ì‚¬ë³¸\n",
      " -ì£¼ë¯¼ë“±ë¡ ë“±ë³¸(ì£¼ì†Œë³€ë™ í¬í•¨) \n",
      "\n",
      "ğŸ“Œ ì¡°ê±´ íƒœê·¸: ë‚¨ì„±, ì—¬ì„±, ì¤‘ìœ„ì†Œë“ 0~50%, ì¤‘ìœ„ì†Œë“ 51~75%, ì¤‘ìœ„ì†Œë“ 76~100%, ì¤‘ìœ„ì†Œë“ 101~200%, ì˜ˆë¹„ë¶€ëª¨/ë‚œì„, ì„ì‚°ë¶€, ì¶œì‚°/ì…ì–‘, ë†ì—…ì¸, ì–´ì—…ì¸, ì¶•ì‚°ì—…ì¸, ì„ì—…ì¸, ì´ˆë“±í•™ìƒ, ì¤‘í•™ìƒ, ê³ ë“±í•™ìƒ, ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ, í•´ë‹¹ì‚¬í•­ì—†ìŒ, ê·¼ë¡œì/ì§ì¥ì¸, êµ¬ì§ì/ì‹¤ì—…ì, ì¥ì• ì¸, êµ­ê°€ë³´í›ˆëŒ€ìƒì, ì§ˆë³‘/ì§ˆí™˜ì, ë¬´ì£¼íƒì„¸ëŒ€\n",
      "--------------------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 3\n",
      "ì„œë¹„ìŠ¤ëª…: í–‰ë³µì£¼íƒ ê³µê¸‰\n",
      "ì„œë¹„ìŠ¤ëª©ì : ë§Œ19~39ì„¸ ì²­ë…„, (ì˜ˆë¹„)ì‹ í˜¼ë¶€ë¶€, í•œë¶€ëª¨ê°€ì¡±, ëŒ€í•™ìƒ ë“± ì Šì€ì¸µì˜ ì£¼ê±°ì•ˆì •ì„ ìœ„í•˜ì—¬ ëŒ€ì¤‘êµí†µì´ í¸ë¦¬í•˜ê±°ë‚˜ ì§ì£¼ê·¼ì ‘ì´ ê°€ëŠ¥í•œ ë¶€ì§€ì— ì£¼ë³€ ì‹œì„¸ë³´ë‹¤ ì €ë ´í•˜ê²Œ ê³µê¸‰\n",
      "ì§€ì›ëŒ€ìƒ: â—‹ ëŒ€í•™ìƒ, ì²­ë…„, (ì˜ˆë¹„)ì‹ í˜¼ë¶€ë¶€, í•œë¶€ëª¨ê°€ì¡±\n",
      "\n",
      "â—‹ ê³ ë ¹ì\n",
      "\n",
      "â—‹ ì£¼ê±°ê¸‰ì—¬ìˆ˜ê¸‰ì\n",
      "\n",
      "â—‹ ì‚°ì—…ë‹¨ì§€ ê·¼ë¡œì\n",
      "ì§€ì›ë‚´ìš©: â—‹ ì‹œì¤‘ ì‹œì„¸ì˜ 60~80% ìˆ˜ì¤€ìœ¼ë¡œ ê³µê³µì„ëŒ€ì£¼íƒê³µê¸‰\n",
      "ì‹ ì²­ë°©ë²•: ë°©ë¬¸, ì¸í„°ë„·\n",
      "ì‹ ì²­ê¸°í•œ: ì ‘ìˆ˜ê¸°ê´€ ë³„ ìƒì´\n",
      "ì„ ì •ê¸°ì¤€: â—‹ ëŒ€í•™ìƒ\n",
      "  - ë¯¸í˜¼ì¸ ë¬´ì£¼íƒìë¡œì„œ ë‹¤ìŒ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ì‚¬ëŒ\n",
      "      * ëŒ€í•™ì— ì¬í•™ ì¤‘ì´ê±°ë‚˜ ë‹¤ìŒ í•™ê¸°ì— ì…í•™ ë˜ëŠ” ë³µí•™ ì˜ˆì •ì¸ ì‚¬ëŒ\n",
      "      * ëŒ€í•™ ë˜ëŠ” ê³ ë“±í•™êµë¥¼ ì¡¸ì—… ë˜ëŠ” ì¤‘í‡´í•œ ë‚ ë¶€í„° 2ë…„ ì´í•˜ì¸ ì‚¬ëŒ\n",
      "  - (ì†Œë“)ë³¸ì¸ ë° ë¶€ëª¨ì˜ ì†Œë“ì´ í‰ê· ì†Œë“ì˜ 100% ì´í•˜ (1ì¸ê°€êµ¬:120%, 2ì¸ê°€êµ¬:110%)\n",
      "  - (ìì‚°)ì„¸ëŒ€ë‚´ ì´ìì‚° 1ì–µì›, ìë™ì°¨ ë¯¸ì†Œìœ \n",
      "\n",
      "â—‹ ì²­ë…„\n",
      "   - ë¯¸í˜¼ì¸ ë¬´ì£¼íƒìë¡œì„œ ë‹¤ìŒ \n",
      "ğŸ“Œ ì¡°ê±´ íƒœê·¸: ë‚¨ì„±, ì—¬ì„±, ì¤‘ìœ„ì†Œë“ 0~50%, ì¤‘ìœ„ì†Œë“ 51~75%, ì¤‘ìœ„ì†Œë“ 76~100%, ì¤‘ìœ„ì†Œë“ 101~200%, ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ, ë¬´ì£¼íƒì„¸ëŒ€\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ìœ ì‚¬ ë¬¸ì„œ + ì¡°ê±´ ì¶œë ¥\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"ğŸ“„ ë¬¸ì„œ {i+1}\")\n",
    "    \n",
    "    # ğŸ”¸ ë¬¸ì„œ ìš”ì•½ (ì•ë¶€ë¶„ë§Œ ì¶œë ¥)\n",
    "    print(doc.page_content[:500])\n",
    "    \n",
    "    # ğŸ”¸ ì¡°ê±´ ì •ë³´ ì¶œë ¥\n",
    "    ì¡°ê±´ë“¤ = doc.metadata.get(\"ì¡°ê±´\", {})\n",
    "    ì„ íƒëœ_ì¡°ê±´ = [k for k, v in ì¡°ê±´ë“¤.items() if v]\n",
    "    \n",
    "    print(f\"ğŸ“Œ ì¡°ê±´ íƒœê·¸: {', '.join(ì„ íƒëœ_ì¡°ê±´) if ì„ íƒëœ_ì¡°ê±´ else 'ì¡°ê±´ ì—†ìŒ'}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# âœ… ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°\n",
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLMì—ê²Œ prompt ìƒì„± â†’ ë‹µë³€ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROMPT ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an assistant for answering questions about Korean government support policies.\n",
    "Use the following retrieved context to answer the user's question.\n",
    "If the answer is not in the context, say \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"\n",
    "Respond in Korean.\n",
    "\n",
    "# Context:\n",
    "{retrieved_text}\n",
    "\n",
    "# Question:\n",
    "{query}\n",
    "\n",
    "# Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Solar Chat ì‘ë‹µ:\n",
      "ì²­ë…„ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ì£¼ê±° ì§€ì›ìœ¼ë¡œëŠ” ì„œìš¸ì‹œ ì²­ë…„ ì›”ì„¸ ì§€ì›, ìš¸ì‚° ì²­ë…„ê°€êµ¬ ì£¼ê±°ë¹„ ì§€ì›ì‚¬ì—… ì§€ì›ì´ ìˆìŠµë‹ˆë‹¤. ì„œìš¸ì‹œ ì²­ë…„ ì›”ì„¸ ì§€ì›ì€ ì„œìš¸ì‹œ ì²­ë…„ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ë©°, ìµœëŒ€ 12ê°œì›” ê°„ ì›” 20ë§Œì› ë²”ìœ„ì—ì„œ ì›”ì„¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ìš¸ì‚° ì²­ë…„ê°€êµ¬ ì£¼ê±°ë¹„ ì§€ì›ì‚¬ì—…ì€ 19ì„¸~39ì„¸ ë¬´ì£¼íƒ ë¯¸í˜¼ ì²­ë…„ê°€êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë©°, ì›” ì„ì°¨ë£Œë¹„ìš© 10ë§Œì›ê³¼ ì›” ì„ì°¨ë³´ì¦ê¸ˆì´ìë¹„ìš© 5ë§Œì›ì„ ì§€ì›í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# âœ… Solar Chat API í˜¸ì¶œ\n",
    "url = \"https://api.upstage.ai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {UPSTAGE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"solar-pro\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "# âœ… ê²°ê³¼ ì¶œë ¥\n",
    "result = response.json()\n",
    "print(\"ğŸ¤– Solar Chat ì‘ë‹µ:\")\n",
    "print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
